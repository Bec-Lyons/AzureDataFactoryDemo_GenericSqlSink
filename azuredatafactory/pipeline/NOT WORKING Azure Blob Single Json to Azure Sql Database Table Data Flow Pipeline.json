{
	"name": "NOT WORKING Azure Blob Single Json to Azure Sql Database Table Data Flow Pipeline",
	"properties": {
		"description": "{\n    \"message\": \"{\\\"StatusCode\\\":\\\"DFExecutorUserError\\\",\\\"Message\\\":\\\"Job 'e1b78984-9f6d-448a-9d29-2ed647af59eb failed due to reason: DF-SYS-01 at Sink 'writeToAzureSqlDatabaseTable': java.util.NoSuchElementException: None.get\\\\njava.util.NoSuchElementException: None.get\\\\n\\\\tat scala.None$.get(Option.scala:347)\\\\n\\\\tat scala.None$.get(Option.scala:345)\\\\n\\\\tat com.microsoft.dataflow.transformers.store.MSSQLWriter$$anonfun$2.applyOrElse(MSSQLStore.scala:241)\\\\n\\\\tat com.microsoft.dataflow.transformers.store.MSSQLWriter$$anonfun$2.applyOrElse(MSSQLStore.scala:236)\\\\n\\\\tat scala.PartialFunction$$anonfun$runWith$1.apply(PartialFunction.scala:141)\\\\n\\\\tat scala.PartialFunction$$anonfun$runWith$1.apply(PartialFunction.scala:140)\\\\n\\\\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\\\\n\\\\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)\\\\n\\\\tat scala.collection.TraversableLike$class.collect(TraversableLike.scala:271)\\\\n\\\\tat scala.collection.mutable.ArrayOps$ofRef.collect(ArrayOps.scala:186)\\\\n\\\\tat com.microsoft.dataflow.transformers.store.MSSQLWriter.columnDefinitions(MSSQLStore.scala:236)\\\\n\\\\tat com.microsoft.dataflow.transformers.store.MSSQLWriter.createTable(MSSQLStore.scala:215)\\\\n\\\\tat com.microsoft.dataflow.transformers.store.JDBCWriter$$anonfun$4$$anonfun$apply$3$$anonfun$apply$mcV$sp$2.apply(JDBCStore.scala:120)\\\\n\\\\tat com.microsoft.dataflow.transformers.store.JDBCWriter$$anonfun$4$$anonfun$apply$3$$anonfun$apply$mcV$sp$2.apply(JDBCStore.scala:119)\\\\n\\\\tat com.microsoft.dataflow.transformers.store.JDBCWriter.withConnection(JDBCStore.scala:74)\\\\n\\\\tat com.microsoft.dataflow.transformers.store.JDBCWriter$$anonfun$4$$anonfun$apply$3.apply$mcV$sp(JDBCStore.scala:119)\\\\n\\\\tat com.microsoft.dataflow.transformers.store.JDBCWriter$$anonfun$4$$anonfun$apply$3.apply(JDBCStore.scala:119)\\\\n\\\\tat com.microsoft.dataflow.transformers.store.JDBCWriter$$anonfun$4$$anonfun$apply$3.apply(JDBCStore.scala:119)\\\\n\\\\tat scala.util.Try$.apply(Try.scala:192)\\\\n\\\\tat com.microsoft.dataflow.transformers.store.JDBCWriter$$anonfun$4.apply(JDBCStore.scala:118)\\\\n\\\\tat com.microsoft.dataflow.transformers.store.JDBCWriter$$anonfun$4.apply(JDBCStore.scala:118)\\\\n\\\\tat com.microsoft.dataflow.FlowRunner$$anonfun$16$$anonfun$apply$25$$anonfun$apply$26.apply(FlowRunner.scala:294)\\\\n\\\\tat com.microsoft.dataflow.FlowRunner$$anonfun$16$$anonfun$apply$25$$anonfun$apply$26.apply(FlowRunner.scala:294)\\\\n\\\\tat com.microsoft.dataflow.FlowCode$$anonfun$2.apply(FlowRunner.scala:32)\\\\n\\\\tat com.microsoft.dataflow.FlowCode$$anonfun$2.apply(FlowRunner.scala:29)\\\\n\\\\tat scala.collection.IndexedSeqOptimized$class.segmentLength(IndexedSeqOptimized.scala:195)\\\\n\\\\tat scala.collection.mutable.ArrayBuffer.segmentLength(ArrayBuffer.scala:48)\\\\n\\\\tat scala.collection.GenSeqLike$class.prefixLength(GenSeqLike.scala:93)\\\\n\\\\tat scala.collection.AbstractSeq.prefixLength(Seq.scala:41)\\\\n\\\\tat scala.collection.IndexedSeqOptimized$class.takeWhile(IndexedSeqOptimized.scala:153)\\\\n\\\\tat scala.collection.mutable.ArrayBuffer.takeWhile(ArrayBuffer.scala:48)\\\\n\\\\tat com.microsoft.dataflow.FlowCode.run(FlowRunner.scala:29)\\\\n\\\\tat com.microsoft.dataflow.DataflowJobFuture$$anonfun$start$1$$anonfun$14.apply(DataflowJobFuture.scala:297)\\\\n\\\\tat com.microsoft.dataflow.DataflowJobFuture$$anonfun$start$1$$anonfun$14.apply(DataflowJobFuture.scala:295)\\\\n\\\\tat scala.util.Success.flatMap(Try.scala:231)\\\\n\\\\tat com.microsoft.dataflow.DataflowJobFuture$$anonfun$start$1.apply$mcV$sp(DataflowJobFuture.scala:295)\\\\n\\\\tat com.microsoft.dataflow.DataflowJobFuture$$anonfun$start$1.apply(DataflowJobFuture.scala:292)\\\\n\\\\tat com.microsoft.dataflow.DataflowJobFuture$$anonfun$start$1.apply(DataflowJobFuture.scala:292)\\\\n\\\\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\\\\n\\\\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\\\\n\\\\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\\\\n\\\\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\\\\n\\\\tat java.lang.Thread.run(Thread.java:748)\\\\n\\\",\\\"Details\\\":\\\"Job 'e1b78984-9f6d-448a-9d29-2ed647af59eb failed due to reason: DF-SYS-01 at Sink 'writeToAzureSqlDatabaseTable': java.util.NoSuchElementException: None.get\\\\njava.util.NoSuchElementException: None.get\\\\n\\\\tat scala.None$.get(Option.scala:347)\\\\n\\\\tat scala.None$.get(Option.scala:345)\\\\n\\\\tat com.microsoft.dataflow.transformers.store.MSSQLWriter$$anonfun$2.applyOrElse(MSSQLStore.scala:241)\\\\n\\\\tat com.microsoft.dataflow.transformers.store.MSSQLWriter$$anonfun$2.applyOrElse(MSSQLStore.scala:236)\\\\n\\\\tat scala.PartialFunction$$anonfun$runWith$1.apply(PartialFunction.scala:141)\\\\n\\\\tat scala.PartialFunction$$anonfun$runWith$1.apply(PartialFunction.scala:140)\\\\n\\\\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\\\\n\\\\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)\\\\n\\\\tat scala.collection.TraversableLike$class.collect(TraversableLike.scala:271)\\\\n\\\\tat scala.collection.mutable.ArrayOps$ofRef.collect(ArrayOps.scala:186)\\\\n\\\\tat com.microsoft.dataflow.transformers.store.MSSQLWriter.columnDefinitions(MSSQLStore.scala:236)\\\\n\\\\tat com.microsoft.dataflow.transformers.store.MSSQLWriter.createTable(MSSQLStore.scala:215)\\\\n\\\\tat com.microsoft.dataflow.transformers.store.JDBCWriter$$anonfun$4$$anonfun$apply$3$$anonfun$apply$mcV$sp$2.apply(JDBCStore.scala:120)\\\\n\\\\tat com.microsoft.dataflow.transformers.store.JDBCWriter$$anonfun$4$$anonfun$apply$3$$anonfun$apply$mcV$sp$2.apply(JDBCStore.scala:119)\\\\n\\\\tat com.microsoft.dataflow.transformers.store.JDBCWriter.withConnection(JDBCStore.scala:74)\\\\n\\\\tat com.microsoft.dataflow.transformers.store.JDBCWriter$$anonfun$4$$anonfun$apply$3.apply$mcV$sp(JDBCStore.scala:119)\\\\n\\\\tat com.microsoft.dataflow.transformers.store.JDBCWriter$$anonfun$4$$anonfun$apply$3.apply(JDBCStore.scala:119)\\\\n\\\\tat com.microsoft.dataflow.transformers.store.JDBCWriter$$anonfun$4$$anonfun$apply$3.apply(JDBCStore.scala:119)\\\\n\\\\tat scala.util.Try$.apply(Try.scala:192)\\\\n\\\\tat com.microsoft.dataflow.transformers.store.JDBCWriter$$anonfun$4.apply(JDBCStore.scala:118)\\\\n\\\\tat com.microsoft.dataflow.transformers.store.JDBCWriter$$anonfun$4.apply(JDBCStore.scala:118)\\\\n\\\\tat com.microsoft.dataflow.FlowRunner$$anonfun$16$$anonfun$apply$25$$anonfun$apply$26.apply(FlowRunner.scala:294)\\\\n\\\\tat com.microsoft.dataflow.FlowRunner$$anonfun$16$$anonfun$apply$25$$anonfun$apply$26.apply(FlowRunner.scala:294)\\\\n\\\\tat com.microsoft.dataflow.FlowCode$$anonfun$2.apply(FlowRunner.scala:32)\\\\n\\\\tat com.microsoft.dataflow.FlowCode$$anonfun$2.apply(FlowRunner.scala:29)\\\\n\\\\tat scala.collection.IndexedSeqOptimized$class.segmentLength(IndexedSeqOptimized.scala:195)\\\\n\\\\tat scala.collection.mutable.ArrayBuffer.segmentLength(ArrayBuffer.scala:48)\\\\n\\\\tat scala.collection.GenSeqLike$class.prefixLength(GenSeqLike.scala:93)\\\\n\\\\tat scala.collection.AbstractSeq.prefixLength(Seq.scala:41)\\\\n\\\\tat scala.collection.IndexedSeqOptimized$class.takeWhile(IndexedSeqOptimized.scala:153)\\\\n\\\\tat scala.collection.mutable.ArrayBuffer.takeWhile(ArrayBuffer.scala:48)\\\\n\\\\tat com.microsoft.dataflow.FlowCode.run(FlowRunner.scala:29)\\\\n\\\\tat com.microsoft.dataflow.DataflowJobFuture$$anonfun$start$1$$anonfun$14.apply(DataflowJobFuture.scala:297)\\\\n\\\\tat com.microsoft.dataflow.DataflowJobFuture$$anonfun$start$1$$anonfun$14.apply(DataflowJobFuture.scala:295)\\\\n\\\\tat scala.util.Success.flatMap(Try.scala:231)\\\\n\\\\tat com.microsoft.dataflow.DataflowJobFuture$$anonfun$start$1.apply$mcV$sp(DataflowJobFuture.scala:295)\\\\n\\\\tat com.microsoft.dataflow.DataflowJobFuture$$anonfun$start$1.apply(DataflowJobFuture.scala:292)\\\\n\\\\tat com.microsoft.dataflow.DataflowJobFuture$$anonfun$start$1.apply(DataflowJobFuture.scala:292)\\\\n\\\\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\\\\n\\\\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\\\\n\\\\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\\\\n\\\\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\\\\n\\\\tat java.lang.Thread.run(Thread.java:748)\\\\n\\\"}\",\n    \"failureType\": \"UserError\",\n    \"target\": \"azureBlobSingleJsontoAzureSqlDatabase\"\n}",
		"activities": [
			{
				"name": "Decide If Delete Original File",
				"type": "IfCondition",
				"dependsOn": [
					{
						"activity": "azureBlobSingleJsontoAzureSqlDatabase",
						"dependencyConditions": [
							"Succeeded"
						]
					}
				],
				"userProperties": [],
				"typeProperties": {
					"expression": {
						"value": "@pipeline().parameters.deleteSourceFile",
						"type": "Expression"
					},
					"ifTrueActivities": [
						{
							"name": "Exec Pipeline Azure Blob Delete Single File",
							"type": "ExecutePipeline",
							"dependsOn": [],
							"userProperties": [],
							"typeProperties": {
								"pipeline": {
									"referenceName": "Azure Blob Delete Single Csv File Pipeline",
									"type": "PipelineReference"
								},
								"waitOnCompletion": true,
								"parameters": {
									"azureBlobConnectionStringSecretName": {
										"value": "@pipeline().parameters.sourceAzureBlobConnectionStringSecretName",
										"type": "Expression"
									},
									"azureBlobContainerName": {
										"value": "@pipeline().parameters.sourceAzureBlobSingleJsonContainerName",
										"type": "Expression"
									},
									"azureBlobFolderPath": {
										"value": "@pipeline().parameters.sourceAzureBlobSingleJsonFolderPath",
										"type": "Expression"
									},
									"azureBlobFileName": {
										"value": "@pipeline().parameters.sourceAzureBlobSingleJsonFileName",
										"type": "Expression"
									}
								}
							}
						}
					]
				}
			},
			{
				"name": "azureBlobSingleJsontoAzureSqlDatabase",
				"type": "ExecuteDataFlow",
				"dependsOn": [],
				"policy": {
					"timeout": "7.00:00:00",
					"retry": 0,
					"retryIntervalInSeconds": 30,
					"secureOutput": false,
					"secureInput": false
				},
				"userProperties": [],
				"typeProperties": {
					"dataflow": {
						"referenceName": "azureBlobSingleJsonToAzureSqlDatabaseDataflow",
						"type": "DataFlowReference",
						"parameters": {
							"sourceConnectionStringSecretName": {
								"value": "'@{pipeline().parameters.sourceAzureBlobConnectionStringSecretName}'",
								"type": "Expression"
							},
							"sinkConnectionStringSecretName": {
								"value": "'@{pipeline().parameters.sinkAzureSqlDatabaseConnectionStringSecretName}'",
								"type": "Expression"
							},
							"sourceObjectName": {
								"value": "'@{concat(\n   pipeline().parameters.sourceAzureBlobConnectionStringSecretName, '/', \n   pipeline().parameters.sourceAzureBlobSingleJsonContainerName, '/', \n   pipeline().parameters.sourceAzureBlobSingleJsonFolderPath, '/', \n   pipeline().parameters.sourceAzureBlobSingleJsonFileName\n)}'",
								"type": "Expression"
							},
							"sinkObjectName": {
								"value": "'@{concat(\n   '[', pipeline().parameters.sinkAzureSqlDatabaseTableSchemaName, '].[', \n   pipeline().parameters.sinkAzureSqlDatabaseTableTableName, ']'\n)}'",
								"type": "Expression"
							},
							"dataFactoryName": {
								"value": "'@{pipeline().DataFactory}'",
								"type": "Expression"
							},
							"dataFactoryPipelineName": {
								"value": "'@{pipeline().Pipeline}'",
								"type": "Expression"
							},
							"dataFactoryPipelineRunId": {
								"value": "'@{pipeline().RunId}'",
								"type": "Expression"
							}
						},
						"datasetParameters": {
							"readFromAzureBlobSingleJson": {
								"azureBlobConnectionStringSecretName": {
									"value": "@pipeline().parameters.sourceAzureBlobConnectionStringSecretName",
									"type": "Expression"
								},
								"azureBlobSingleJsonContainerName": {
									"value": "@pipeline().parameters.sourceAzureBlobSingleJsonContainerName",
									"type": "Expression"
								},
								"azureBlobSingleJsonFolderPath": {
									"value": "@pipeline().parameters.sourceAzureBlobSingleJsonFolderPath",
									"type": "Expression"
								},
								"azureBlobSingleJsonFileName": {
									"value": "@pipeline().parameters.sourceAzureBlobSingleJsonFileName",
									"type": "Expression"
								}
							},
							"writeToAzureSqlDatabaseTable": {
								"azureSqlDatabaseConnectionStringSecretName": {
									"value": "@pipeline().parameters.sinkAzureSqlDatabaseConnectionStringSecretName",
									"type": "Expression"
								},
								"azureSqlDatabaseTableSchemaName": {
									"value": "@pipeline().parameters.sinkAzureSqlDatabaseTableSchemaName",
									"type": "Expression"
								},
								"azureSqlDatabaseTableTableName": {
									"value": "@pipeline().parameters.sinkAzureSqlDatabaseTableTableName",
									"type": "Expression"
								}
							}
						}
					},
					"compute": {
						"coreCount": 8,
						"computeType": "General"
					}
				}
			}
		],
		"parameters": {
			"sourceAzureBlobConnectionStringSecretName": {
				"type": "string"
			},
			"sourceAzureBlobSingleJsonContainerName": {
				"type": "string"
			},
			"sourceAzureBlobSingleJsonFolderPath": {
				"type": "string"
			},
			"sourceAzureBlobSingleJsonFileName": {
				"type": "string"
			},
			"sinkAzureSqlDatabaseConnectionStringSecretName": {
				"type": "string"
			},
			"sinkAzureSqlDatabaseTableSchemaName": {
				"type": "string"
			},
			"sinkAzureSqlDatabaseTableTableName": {
				"type": "string"
			},
			"deleteSourceFile": {
				"type": "bool"
			}
		},
		"folder": {
			"name": "Source Azure Blob Single Json/Data Flow"
		},
		"annotations": []
	}
}