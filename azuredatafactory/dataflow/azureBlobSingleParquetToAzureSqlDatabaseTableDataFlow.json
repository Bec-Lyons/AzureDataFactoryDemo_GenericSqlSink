{
	"name": "azureBlobSingleParquetToAzureSqlDatabaseTableDataFlow",
	"properties": {
		"folder": {
			"name": "Source Azure Single Parquet"
		},
		"type": "MappingDataFlow",
		"typeProperties": {
			"sources": [
				{
					"dataset": {
						"referenceName": "azureBlobSingleParquetFileNameDataset",
						"type": "DatasetReference"
					},
					"name": "readFromAzureBlobSingleParquet"
				}
			],
			"sinks": [
				{
					"dataset": {
						"referenceName": "azureSqlDatabaseTableDataset",
						"type": "DatasetReference"
					},
					"name": "writeToAzureBlobSingleParquet"
				}
			],
			"transformations": [
				{
					"name": "EnrichWithRuntimeMetadata"
				}
			],
			"script": "\nparameters{\n\tsourceConnectionSecretName as string,\n\tsinkConnectionStringSecretName as string,\n\tsourceObjectName as string,\n\tsinkObjectName as string,\n\tdataFactoryName as string,\n\tdataFactoryPipelineName as string,\n\tdataFactoryPipelineRunId as string\n}\nsource(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tformat: 'parquet') ~> readFromAzureBlobSingleParquet\nreadFromAzureBlobSingleParquet derive({__sourceConnectionStringSecretName} = $sourceConnectionSecretName,\n\t\t{__sinkConnectionStringSecretName} = $sinkConnectionStringSecretName,\n\t\t{__sourceObjectName} = $sourceObjectName,\n\t\t{__sinkObjectName} = $sinkObjectName,\n\t\t{__dataFactoryName} = $dataFactoryName,\n\t\t{__dataFactoryPipelineName} = $dataFactoryPipelineName,\n\t\t{__dataFactoryPipelineRunId} = $dataFactoryPipelineRunId) ~> EnrichWithRuntimeMetadata\nEnrichWithRuntimeMetadata sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tdeletable:false,\n\tinsertable:true,\n\tupdateable:false,\n\tupsertable:false,\n\tformat: 'table',\n\tpartitionBy('hash', 1),\n\tquoteAll: true) ~> writeToAzureBlobSingleParquet"
		}
	}
}